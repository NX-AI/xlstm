{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../..\")\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xlstm.xlstm_large.model import xLSTMLargeConfig, xLSTMLarge\n",
    "from mlstm_kernels.torch import get_available_mlstm_step_kernels, get_available_mlstm_kernels, get_available_mlstm_sequence_kernels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['chunkwise--native_autograd',\n",
       "  'chunkwise--native_custbw',\n",
       "  'chunkwise--triton_limit_chunk',\n",
       "  'chunkwise--triton_xl_chunk',\n",
       "  'chunkwise--triton_xl_chunk_siging',\n",
       "  'parallel--native_autograd',\n",
       "  'parallel--native_custbw',\n",
       "  'parallel--native_stablef_autograd',\n",
       "  'parallel--native_stablef_custbw',\n",
       "  'parallel--triton_limit_headdim',\n",
       "  'parallel--native_siging_autograd',\n",
       "  'parallel--native_siging_custbw'],\n",
       " ['native', 'triton'],\n",
       " ['native_sequence__native', 'native_sequence__triton'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_available_mlstm_kernels(), get_available_mlstm_step_kernels(), get_available_mlstm_sequence_kernels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlstm_config = xLSTMLargeConfig(\n",
    "    embedding_dim=512,\n",
    "    num_heads=4,\n",
    "    num_blocks=6,\n",
    "    vocab_size=2048,\n",
    "    return_last_states=True,\n",
    "    mode=\"inference\",\n",
    "    chunkwise_kernel=\"chunkwise--triton_xl_chunk\", # xl_chunk == TFLA kernels\n",
    "    sequence_kernel=\"native_sequence__triton\",\n",
    "    step_kernel=\"triton\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlstm = xLSTMLarge(xlstm_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "xLSTMLarge(\n",
       "  (embedding): Embedding(2048, 512)\n",
       "  (backbone): xLSTMLargeBlockStack(\n",
       "    (blocks): ModuleList(\n",
       "      (0-5): 6 x mLSTMBlock(\n",
       "        (norm_mlstm): RMSNorm()\n",
       "        (mlstm_layer): mLSTMLayer(\n",
       "          (q): Linear(in_features=512, out_features=256, bias=False)\n",
       "          (k): Linear(in_features=512, out_features=256, bias=False)\n",
       "          (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (ogate_preact): Linear(in_features=512, out_features=512, bias=False)\n",
       "          (igate_preact): Linear(in_features=512, out_features=4, bias=True)\n",
       "          (fgate_preact): Linear(in_features=512, out_features=4, bias=True)\n",
       "          (ogate_act_fn): Sigmoid()\n",
       "          (mlstm_backend): mLSTMBackend(mLSTMBackendConfig(chunkwise_kernel='chunkwise--triton_xl_chunk', sequence_kernel='native_sequence__triton', step_kernel='triton', mode='inference', chunk_size=64, return_last_states=True, autocast_kernel_dtype='bfloat16', eps=1e-06, inference_state_dtype='float32'))\n",
       "          (multihead_norm): MultiHeadLayerNorm()\n",
       "          (out_proj): Linear(in_features=512, out_features=512, bias=False)\n",
       "        )\n",
       "        (norm_ffn): RMSNorm()\n",
       "        (ffn): FeedForward(\n",
       "          (proj_up_gate): Linear(in_features=512, out_features=1408, bias=False)\n",
       "          (proj_up): Linear(in_features=512, out_features=1408, bias=False)\n",
       "          (proj_down): Linear(in_features=1408, out_features=512, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (out_norm): RMSNorm()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=2048, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlstm = xlstm.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 256])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = torch.randint(0, 2048, (3, 256)).to(\"cuda\")\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = xlstm(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(out) == 2:\n",
    "    out, state = out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape[1:] == (256, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([0, 1, 2, 3, 4, 5])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(state), len(state[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 1]), torch.Size([3, 256]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input[:, 0:1].shape, input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "step_out, step_state = xlstm(input[:, 0:1], state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 2048])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_chunkwise, last_state_chunkwise = xlstm(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_steps = []\n",
    "state = None\n",
    "for i in range(input.shape[1]):\n",
    "    out_step, state = xlstm(input[:, i:i + 1], state)\n",
    "    out_steps.append(out_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_steps = torch.cat(out_steps, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 256, 2048]), torch.Size([3, 256, 2048]))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_steps.shape, out_chunkwise.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0085, device='cuda:0', grad_fn=<MaxBackward1>)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out_chunkwise - out_steps).abs().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.allclose(out_chunkwise, out_steps, atol=7e-2, rtol=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['embedding.weight',\n",
       " 'backbone.blocks.0.norm_mlstm.weight',\n",
       " 'backbone.blocks.0.mlstm_layer.q.weight',\n",
       " 'backbone.blocks.0.mlstm_layer.k.weight',\n",
       " 'backbone.blocks.0.mlstm_layer.v.weight',\n",
       " 'backbone.blocks.0.mlstm_layer.ogate_preact.weight',\n",
       " 'backbone.blocks.0.mlstm_layer.igate_preact.weight',\n",
       " 'backbone.blocks.0.mlstm_layer.igate_preact.bias',\n",
       " 'backbone.blocks.0.mlstm_layer.fgate_preact.weight',\n",
       " 'backbone.blocks.0.mlstm_layer.fgate_preact.bias',\n",
       " 'backbone.blocks.0.mlstm_layer.multihead_norm.weight',\n",
       " 'backbone.blocks.0.mlstm_layer.out_proj.weight',\n",
       " 'backbone.blocks.0.norm_ffn.weight',\n",
       " 'backbone.blocks.0.ffn.proj_up_gate.weight',\n",
       " 'backbone.blocks.0.ffn.proj_up.weight',\n",
       " 'backbone.blocks.0.ffn.proj_down.weight',\n",
       " 'backbone.blocks.1.norm_mlstm.weight',\n",
       " 'backbone.blocks.1.mlstm_layer.q.weight',\n",
       " 'backbone.blocks.1.mlstm_layer.k.weight',\n",
       " 'backbone.blocks.1.mlstm_layer.v.weight',\n",
       " 'backbone.blocks.1.mlstm_layer.ogate_preact.weight',\n",
       " 'backbone.blocks.1.mlstm_layer.igate_preact.weight',\n",
       " 'backbone.blocks.1.mlstm_layer.igate_preact.bias',\n",
       " 'backbone.blocks.1.mlstm_layer.fgate_preact.weight',\n",
       " 'backbone.blocks.1.mlstm_layer.fgate_preact.bias',\n",
       " 'backbone.blocks.1.mlstm_layer.multihead_norm.weight',\n",
       " 'backbone.blocks.1.mlstm_layer.out_proj.weight',\n",
       " 'backbone.blocks.1.norm_ffn.weight',\n",
       " 'backbone.blocks.1.ffn.proj_up_gate.weight',\n",
       " 'backbone.blocks.1.ffn.proj_up.weight',\n",
       " 'backbone.blocks.1.ffn.proj_down.weight',\n",
       " 'backbone.blocks.2.norm_mlstm.weight',\n",
       " 'backbone.blocks.2.mlstm_layer.q.weight',\n",
       " 'backbone.blocks.2.mlstm_layer.k.weight',\n",
       " 'backbone.blocks.2.mlstm_layer.v.weight',\n",
       " 'backbone.blocks.2.mlstm_layer.ogate_preact.weight',\n",
       " 'backbone.blocks.2.mlstm_layer.igate_preact.weight',\n",
       " 'backbone.blocks.2.mlstm_layer.igate_preact.bias',\n",
       " 'backbone.blocks.2.mlstm_layer.fgate_preact.weight',\n",
       " 'backbone.blocks.2.mlstm_layer.fgate_preact.bias',\n",
       " 'backbone.blocks.2.mlstm_layer.multihead_norm.weight',\n",
       " 'backbone.blocks.2.mlstm_layer.out_proj.weight',\n",
       " 'backbone.blocks.2.norm_ffn.weight',\n",
       " 'backbone.blocks.2.ffn.proj_up_gate.weight',\n",
       " 'backbone.blocks.2.ffn.proj_up.weight',\n",
       " 'backbone.blocks.2.ffn.proj_down.weight',\n",
       " 'backbone.blocks.3.norm_mlstm.weight',\n",
       " 'backbone.blocks.3.mlstm_layer.q.weight',\n",
       " 'backbone.blocks.3.mlstm_layer.k.weight',\n",
       " 'backbone.blocks.3.mlstm_layer.v.weight',\n",
       " 'backbone.blocks.3.mlstm_layer.ogate_preact.weight',\n",
       " 'backbone.blocks.3.mlstm_layer.igate_preact.weight',\n",
       " 'backbone.blocks.3.mlstm_layer.igate_preact.bias',\n",
       " 'backbone.blocks.3.mlstm_layer.fgate_preact.weight',\n",
       " 'backbone.blocks.3.mlstm_layer.fgate_preact.bias',\n",
       " 'backbone.blocks.3.mlstm_layer.multihead_norm.weight',\n",
       " 'backbone.blocks.3.mlstm_layer.out_proj.weight',\n",
       " 'backbone.blocks.3.norm_ffn.weight',\n",
       " 'backbone.blocks.3.ffn.proj_up_gate.weight',\n",
       " 'backbone.blocks.3.ffn.proj_up.weight',\n",
       " 'backbone.blocks.3.ffn.proj_down.weight',\n",
       " 'backbone.blocks.4.norm_mlstm.weight',\n",
       " 'backbone.blocks.4.mlstm_layer.q.weight',\n",
       " 'backbone.blocks.4.mlstm_layer.k.weight',\n",
       " 'backbone.blocks.4.mlstm_layer.v.weight',\n",
       " 'backbone.blocks.4.mlstm_layer.ogate_preact.weight',\n",
       " 'backbone.blocks.4.mlstm_layer.igate_preact.weight',\n",
       " 'backbone.blocks.4.mlstm_layer.igate_preact.bias',\n",
       " 'backbone.blocks.4.mlstm_layer.fgate_preact.weight',\n",
       " 'backbone.blocks.4.mlstm_layer.fgate_preact.bias',\n",
       " 'backbone.blocks.4.mlstm_layer.multihead_norm.weight',\n",
       " 'backbone.blocks.4.mlstm_layer.out_proj.weight',\n",
       " 'backbone.blocks.4.norm_ffn.weight',\n",
       " 'backbone.blocks.4.ffn.proj_up_gate.weight',\n",
       " 'backbone.blocks.4.ffn.proj_up.weight',\n",
       " 'backbone.blocks.4.ffn.proj_down.weight',\n",
       " 'backbone.blocks.5.norm_mlstm.weight',\n",
       " 'backbone.blocks.5.mlstm_layer.q.weight',\n",
       " 'backbone.blocks.5.mlstm_layer.k.weight',\n",
       " 'backbone.blocks.5.mlstm_layer.v.weight',\n",
       " 'backbone.blocks.5.mlstm_layer.ogate_preact.weight',\n",
       " 'backbone.blocks.5.mlstm_layer.igate_preact.weight',\n",
       " 'backbone.blocks.5.mlstm_layer.igate_preact.bias',\n",
       " 'backbone.blocks.5.mlstm_layer.fgate_preact.weight',\n",
       " 'backbone.blocks.5.mlstm_layer.fgate_preact.bias',\n",
       " 'backbone.blocks.5.mlstm_layer.multihead_norm.weight',\n",
       " 'backbone.blocks.5.mlstm_layer.out_proj.weight',\n",
       " 'backbone.blocks.5.norm_ffn.weight',\n",
       " 'backbone.blocks.5.ffn.proj_up_gate.weight',\n",
       " 'backbone.blocks.5.ffn.proj_up.weight',\n",
       " 'backbone.blocks.5.ffn.proj_down.weight',\n",
       " 'backbone.out_norm.weight',\n",
       " 'lm_head.weight']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(xlstm.state_dict().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstmpt240cu124",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
